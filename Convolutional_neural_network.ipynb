{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "P4nfsiXZCd9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scratch\n",
        "class CNN_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(net,self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,32,3,1)  #input,filters,kernel_size,stride\n",
        "    self.conv2=nn.Conv2d(32,64,3,1)\n",
        "    self.fc1=nn.Linear(1233,120)    # input_feature,output 120\n",
        "    self.fc2=nn.Linear(120,10)\n",
        "\n",
        "  def forword(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=F.relu(x)\n",
        "    x=F.max_pool2d(x,2)\n",
        "    x=torch.flatten(x,1) # resize to one diminsion\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    output=F.log_softmax(x,dim=1)\n",
        "    return output\n",
        "\n",
        "model=net()\n",
        "\n",
        "#data\n",
        "train_data=DataLoader(tain_data,batch_sampler=4,shuffle=4,transforms=ToTensor())\n",
        "test_data=DataLoader(tst_data,batch_size=5shuffle=4,transforms=ToTensor())\n",
        "\n",
        "# loss and optimiser\n",
        "optimiser=optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion=nn.MSELoss()\n",
        "\n",
        "#training loop\n",
        "num_epoch=10\n",
        "for epoch in range(num_epoch):\n",
        "  for input,labels in train_data:\n",
        "\n",
        "    #zero grad\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    #forward\n",
        "    output=model(input)\n",
        "    _,predict=output.max(1)\n",
        "    loss=criterion(output,labels)\n",
        "\n",
        "    #backpropogation\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "print('training_loop completed')\n",
        "\n",
        "\n",
        "# model evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  output=model(input)\n",
        "  _,predict=output.max(1)\n",
        "  print(predict)\n",
        "\n",
        "# prepossing\n",
        "prepross=transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip()\n",
        "    transforms.RandomResizedCrop(120)\n",
        "    transforms.ToTensor()\n",
        "    transforms.F.normalize([1,1,1],[1,1,1])\n",
        "])\n",
        "\n",
        "image=prepross(image)"
      ],
      "metadata": {
        "id": "XzeSxmSd0fb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets\n",
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jRYHx5F9C1R",
        "outputId": "cf21b14f-7ff6-460b-8c97-9c219a053c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 79789945.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "zjHKZdCZ172p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimiser\n",
        "crition=nn.CrossEntropyLoss()\n",
        "optimiser=optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "nrQUZf4A9cM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop (pretrianed model)\n",
        "model=models.resnet18(pretrained=True)\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    for input,labels in train_data:\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "      #forward pass\n",
        "      output=model(input)\n",
        "      _,predict=output.max(1)\n",
        "      loss=crition(output,labels)\n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      print(f'print{loss}')\n",
        "\n",
        "torch.save(model.state_dict(),'model.pth')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for input,labels in test_data:\n",
        "    output=model(input)\n",
        "    _,predict=output.max(1)\n",
        "    loss=crition(output,labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YNvKQ5FJ9Lwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To alter the data into required form\n",
        "prepross=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(120)\n",
        "    transforms.RandomHorizontalFlip()\n",
        "    transforms.ToTensor()\n",
        "    transforms.Normalize([1,2,2],[1,1,1])\n",
        "])\n",
        "\n",
        "image=prepross(image)"
      ],
      "metadata": {
        "id": "_mK1GlexvhPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alter the entire data into required form\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val':transforms.Compose([\n",
        "        transforms.RandomResizedCrop(120)\n",
        "    ]) }"
      ],
      "metadata": {
        "id": "9NdqfdMzvu0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the setps and function and uses"
      ],
      "metadata": {
        "id": "dmKvknl8vUHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example tensor with shape [32, 1, 5, 5]\n",
        "t = torch.randn(32, 1, 5, 5)\n",
        "# Flatten the tensor starting from the second dimension\n",
        "flattened_t = torch.flatten(t, 1)\n",
        "print(flattened_t.shape) # Output: torch.Size([32, 25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B5a9Jc1_cKq",
        "outputId": "524d5a12-e687-4814-f116-c875751d60e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the model accuracy with for generative model GAN\n",
        "from pytorch_gan_matrics import InceptionScore, FrechetInceptionDistance\n",
        "\n",
        "with torch.no_grad():\n",
        "  fake_image=generator(torch.randn(real_images.size(0), 100))\n",
        "# It uses a pre-trained Inceptionv3 model to calculate the expected log-likelihood of the generated images. A higher IS indicates that the generated images are more likely to be realistic and diverse.\n",
        "InceptionScore=InceptionScore(fake_image,real_image)\n",
        "\n",
        "# A lower FID indicates that the generated images are closer to the real images in the feature space, suggesting better performance of the GAN.\n",
        "FrechetInceptionDistance=FrechetInceptionDistance(fake_image,real_image)\n"
      ],
      "metadata": {
        "id": "10UDaJ9WCU5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keras framework**"
      ],
      "metadata": {
        "id": "PGD4u6HjQgWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequencial\n",
        "from keras.layers import Dense\n",
        "from keras.optimiser import Adam\n",
        "\n",
        "def genrator():\n",
        "  model.Sequencial()\n",
        "  model.add(Dense(unit=100,input_dim=100,activation='relu'))\n",
        "  model.add(Dense(unit=50,activation='relu'))\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "SWC-P9b-Nw7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # In PyTorch, there are two ways to flatten a tensor. The first way is to use the torch.flatten() method. This method takes a tensor as input and returns a one-dimensional tensor. The second way is to use the view() method. This method takes a tensor and a new shape as input and returns a tensor with the new shape.\n",
        "# # Here is an example of how to use the torch.flatten() method to flatten a tensor:\n",
        "# # Python\n",
        "\n",
        "# import torch\n",
        "\n",
        "# # Create a tensor\n",
        "# x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "# # Flatten the tensor\n",
        "# y = torch.flatten(x)\n",
        "# # Print the flattened tensor\n",
        "# print(y)\n",
        "# # Output:\n",
        "# # Code\n",
        "\n",
        "# # tensor([1, 2, 3, 4, 5, 6])\n",
        "# # Here is an example of how to use the view() method to flatten a tensor:\n",
        "# # Python\n",
        "# import torch\n",
        "\n",
        "# # Create a tensor\n",
        "# x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# # Flatten the tensor\n",
        "# y = x.view(-1)\n",
        "\n",
        "# # Print the flattened tensor\n",
        "# print(y)\n",
        "# Output:\n",
        "# # Code\n",
        "\n",
        "# # tensor([1, 2, 3, 4, 5, 6])\n",
        "# # As you can see, both methods produce the same result. The torch.flatten() method is more concise, but the view() method is more flexible. You can use the view() method to reshape a tensor into any shape, not just a one-dimensional shape.\n",
        "# # Here is an example of how to use the view() method to reshape a tensor into a two-dimensional shape:\n",
        "# # Python\n",
        "\n",
        "# import torch\n",
        "\n",
        "# # Create a tensor\n",
        "# x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "# # Reshape the tensor into a two-dimensional shape\n",
        "# y = x.view(2, 3)\n",
        "# # Print the reshaped tensor\n",
        "# print(y)\n",
        "# # Output:\n",
        "# # Code\n",
        "# # tensor([[1, 2, 3],\n",
        "# #         [4, 5, 6]])\n",
        "# # The view() method is a powerful tool that can be used to reshape tensors into any shape you need."
      ],
      "metadata": {
        "id": "bB0HKe_6Qn3b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x=np.random.random(2)\n",
        "print(x)\n",
        "y=np.random.randn(2,3)\n",
        "print(y)\n",
        "z=np.random.randint(2,5,(2,3))\n",
        "print(f'random int {z} diminsion {z.ndim}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiU7KOUWbpm4",
        "outputId": "93d371f1-bdc8-427c-b909-f9ea987c249e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8557635  0.69988872]\n",
            "[[ 2.28056698e+00  5.53747128e-01 -5.49000260e-01]\n",
            " [-1.04454308e+00  7.36904767e-04 -1.89026144e+00]]\n",
            "random int [[2 3 2]\n",
            " [4 2 2]] diminsion 2\n"
          ]
        }
      ]
    }
  ]
}